{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning: Chapter 2\n",
    "\n",
    "\n",
    "Example:  Classify handwritten digits\n",
    "\n",
    "* grayscale images, 28x28 pixels into 10 categories\n",
    "* [MNISt](https://en.wikipedia.org/wiki/MNIST_database) dataset: 60k training images, 10k test images\n",
    "\n",
    "\n",
    "Terminology:\n",
    "\n",
    "* **Class**: a category in a classification problem \n",
    "* **Sample**: datapoints\n",
    "* **Label** class associatied with a specific sample\n",
    "\n",
    "MNIST database is preloaded in KERASin set of four Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `train_images` and `train_labels` frm the training set\n",
    "* `test_images` and `test_labels` is test set on which model will be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train_image = (60000, 28, 28)\n",
      "Length train_labels = 60000\n",
      "Shape test_images= (10000, 28, 28)\n",
      "Length test_labels = 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape train_image = {train_images.shape}\")\n",
    "print(f\"Length train_labels = {len(train_labels)}\")\n",
    "print(f\"Shape test_images= {test_images.shape}\")\n",
    "print(f\"Length test_labels = {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow: \n",
    "\n",
    "1. feed neuronal network training data\n",
    "2. associate images with labels\n",
    "3. produce predictions for test images\n",
    "4. verify whether predictions match test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* layer: is a filter\n",
    "* layers extract representations of data fed into them.\n",
    "* layers are chained\n",
    "\n",
    "Network above consists of a sequence of two dense layers that are *densely* connected (or *fully* connected) neural layers. The second layer is a 10 way *softmax* layer which returns 10 probability scores (summing to 1). Each score will give probability that current digit belongs to one of the 10 digit classes.\n",
    "\n",
    "To make the network ready for training need to pick three more things as part of the *compilation* step: \n",
    "\n",
    "* an optimizer (method to update network)\n",
    "* a loss function (how network measures performance on training data)\n",
    "* metrics to monitor during training and testing (here: accuracy of classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A representation of the work flow is below:\n",
    "\n",
    "<img src=\"https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/01fig09.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* reshape images into a `float32` array of shape (60000, 28*28)\n",
    "* rescale 8 bit images into values in interval `[0, 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 *28))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* categorically encode labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train network.  Call network's fit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/clemenskaminski/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2562 - accuracy: 0.9264\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1041 - accuracy: 0.9694\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0680 - accuracy: 0.9804\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0498 - accuracy: 0.9857\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0377 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63f273f90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs =5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* evaluate how good network is at categorising unknown data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 37us/step\n",
      "test_acc: 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is lower than the training set accuracy.  This is an example of *overfitting*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is in the workflow in short for generating a DL network in Keras. In what follows, we discuss what's behind the working.  We'll discuss data, tensors, tensor operations, data transoformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types of data we are dealing with are:\n",
    "\n",
    "* Vector data: e.g. dataset of text documents where each document is represented by the counts of how many times each word in a dictionary appears in it.  e.g. tensor of shape `(500, 20000)` might describe 500 documents and the count for each of the words contained in a dictionary of 20000 words.\n",
    "\n",
    "* Time series data: e.g.stock prices as a tensor of rank 3: 250 days with values recorded every minute (390 working minutes per day), recording low, high and current price for each minute `(250, 390, 3)`\n",
    "\n",
    "* Image data: tensor of rank 4: e.g. 128 images, 256 x 256 pixels, 3 colour channels. `(128, 256, 256, 3)`. note Tensorflow convention for order is `(samples, height, width, color_depth)` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor attributes\n",
    "\n",
    "* Number of axes (rank)\n",
    "* shape: dimension of tensor along each axis\n",
    "* Data type (usually `dtype` in python libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_images =  (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print('shape of train_images = ', train_images.shape)  #Note: above we have vectorised 28x28 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y = (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "y = np.reshape(train_images, (60000, 28,28)) #reshape into tensor of rank 3 (sample, height, width)\n",
    "print('shape of y =', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit = y[3]\n",
    "digit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = y[34001]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing tensors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing just bottom half of 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = y[34001, 15:, :]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter=0\n",
    "start_index = 1011\n",
    "tiles = 7\n",
    "images = y[start_index:start_index+tiles]\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "for i in range(1,len(images)+1):\n",
    "    sub = fig.add_subplot(1, len(images), i)\n",
    "    sub.axis('off')\n",
    "    sub.imshow(images[i-1])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data batches\n",
    "\n",
    "the first axes (axis 0) is called the **sample axis**.  Usually the entire dataset can't be processed at once and one needs to break the dataset into smaller **batches**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1 = train_images[:128]\n",
    "\n",
    "batch_4 = train_images[128*4:128*(4+1)]  #batch n is from dataset[128*n:128*(n+1)] \n",
    "\n",
    "len(batch_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All transformations learned by DNN can be reduced to a small number of tensor operations (add, multiply, etc)\n",
    "\n",
    "E.g.\n",
    "```python\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape=(28 * 28,)))\n",
    "```\n",
    "\n",
    "this layer cab be interpreted as a function that takes a 2D tensor (vecor samples) and returns another 2D tensor.\n",
    "\n",
    "The function is:\n",
    "\n",
    "```python\n",
    "output = relu(dot(W, input) + b\n",
    "```\n",
    "\n",
    "* This includes a dot product between a 2D tensor W and an input tensor and adds a vector b. \n",
    "* It also includes a **rectified linear unit** function defined as `max(x, 0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectified linear Unit - relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    '''Naive implementation of relu (rectified linear unit) function\n",
    "    takes tensor x of rank 2\n",
    "    ''' \n",
    "    assert len(x.shape) == 2, 'x has more than 2 axes, not an image!'\n",
    "    x = x.copy()    #produce a copy of x without overwriting input tensor\n",
    "   \n",
    "    \n",
    "    for i in range(0, x.shape[0]):\n",
    "        for j in range(0, x.shape[1]):\n",
    "            x[i, j]=max(x[i,j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=\n",
      "[[ 0.15304079  0.11658962  0.25870324 -0.55225153]\n",
      " [-0.28590247  0.30955119 -0.67407404 -0.76107192]\n",
      " [-0.03593688  0.42629766  0.23669738  0.62289514]] \n",
      "\n",
      "Relu(x) = naive_relu(x) =\n",
      "[[0.15304079 0.11658962 0.25870324 0.        ]\n",
      " [0.         0.30955119 0.         0.        ]\n",
      " [0.         0.42629766 0.23669738 0.62289514]]\n"
     ]
    }
   ],
   "source": [
    "x = 2.0*(np.random.random((3,4))-0.5)  #random.random only produces positive numbers in (0, 1)\n",
    "\n",
    "print(f\"x=\\n{x} \\n\")\n",
    "print(f\"Relu(x) = naive_relu(x) =\\n{naive_relu(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same is achieved with the very simple inbuilt numpy method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relu(x) = np.maximum(x, 0) =\n",
      "[[0.15304079 0.11658962 0.25870324 0.        ]\n",
      " [0.         0.30955119 0.         0.        ]\n",
      " [0.         0.42629766 0.23669738 0.62289514]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Relu(x) = np.maximum(x, 0) =\\n{np.maximum(x,0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_addition(x, y):\n",
    "    assert len(x.shape)== 2, \"Shape of x or y not rank 2!\"\n",
    "    assert x.shape == y.shape, \"Shape of x and y not same!\"\n",
    "    \n",
    "    x=x.copy()\n",
    "    y=y.copy()\n",
    "    \n",
    "    for i in range(0, x.shape[0]):\n",
    "        for j in range(0, x.shape[1]):\n",
    "            x[i,j]+=y[i,j]\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =\n",
      "[[2 3 2]\n",
      " [3 4 0]]\n",
      "b =\n",
      "[[4 2 4]\n",
      " [1 1 4]]\n",
      "a + b = naive_addition(a, b) =\n",
      "[[6 5 6]\n",
      " [4 5 4]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(5, size=(2,3))\n",
    "print(f\"a =\\n{a}\")\n",
    "\n",
    "b = np.random.randint(5, size=(2,3))\n",
    "print(f\"b =\\n{b}\")\n",
    "\n",
    "print(f\"a + b = naive_addition(a, b) =\\n{naive_addition(a, b)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Means stretching dimensions of lower rank tensor to those of higher rank tensor for efficient computation.\n",
    "\n",
    "See [broadcasting article](https://numpy.org/devdocs/user/theory.broadcasting.html)\n",
    "\n",
    "* works from last axis backward to front\n",
    "* final dimensions must match\n",
    "\n",
    "E.g. adding `1` to `[1,2,3]` is the same as broadcasting `1` to `[1,1,1]` and adding `[1,1,1]` to `[1,2,3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,4)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=\n",
      " [[[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]]\n",
      "\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]]]\n",
      "\n",
      "rank of y: 3\n",
      "\n",
      "shape of y: (2, 3, 10)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(1,11).astype(float)\n",
    "y = np.ones((2, 3, 10)).astype(float)\n",
    "y[:]=x\n",
    "print('y=\\n',y)\n",
    "\n",
    "print('\\nrank of y:', y.ndim)\n",
    "\n",
    "print('\\nshape of y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-based optimisation\n",
    "\n",
    "each neural layer transforms input data as follows:\n",
    "\n",
    "```\n",
    "output = relu(dot(W, input) +b)\n",
    "```\n",
    "\n",
    "where W and b are tensors that are attributes of layers, called weights (*kernel*) or trainable parameters (*bias*) of the layer.  Initially, this does nothing useful, but gradually W and b are adjusted, based on feedback signal.  This adjustment takes place in a *training loop*.  Specifically\n",
    "\n",
    "1. Draw batch of training samples `x` and corresponding targets `y`\n",
    "1. Run network on `x` (called *forward pass*) to obain `y_predicted`\n",
    "1. Compute loss of network on batch, a measure of mismatch between `y_predicted` and `y`\n",
    "1. Update  weights of `W`, `b` so that loss is reduced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat, until loss is low: The network has now learned to map inputs to their correct targets.  \n",
    "* Step 1 is simple: just I/O code.\n",
    "* Steps 2 and 3 are merely application of a handful of tensor ops.\n",
    "* Step 4 is the difficult part.  How do we decide whether `W` and `b` coefficients should be increased or decreased? And by how much?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could do latter by freezing all coefficients except one, which you vary and recalculate loss.  If loss greater, change coefficient accordingly, etc.  Repeat sequentially for all coefficients. Problem: Terribly inefficient! There may be 10s or even 100s of thousands of coefficients to optimise: this makes problem intractable.  However: all operations described are differentiable. Better way: compute **gradient** of the loss wih regards to network coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivative:**\n",
    "\n",
    "Approximate `f` around a point `p` as:\n",
    "\n",
    "`f(x + epsilon_x) = y + a * epsilon_x`\n",
    "\n",
    "The slope `a` is called the derivative of `f` in `p`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vector dot product\n",
    "\n",
    "\n",
    "$$ z = \\vec{x} \\cdot \\vec{y}$$\n",
    "\n",
    "where $z$ is a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x,y):\n",
    "    assert len(x.shape)==1, \"rank != 1: x not a vector!\"\n",
    "    assert len(y.shape)==1, \"rank != 1: y not a vector!\"\n",
    "    assert x.shape[0]==y.shape[0], \"len(x) != len(y): shapes incompatible!\"\n",
    "    \n",
    "    x=x.copy()\n",
    "    y=y.copy() #ensures that original x, y not overridden\n",
    "    z=0.0\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        z+=x[i]*y[i]\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3].[4 5 6]=\n",
      " 32.0\n"
     ]
    }
   ],
   "source": [
    "x=np.array([1,2,3])\n",
    "y=np.array([4,5,6])\n",
    "\n",
    "print(f\"{x}.{y}=\\n {naive_vector_dot(x, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix - vector product:\n",
    "\n",
    "$$ \\vec{z} = \\mathbf{x} \\cdot \\vec{y}$$\n",
    "\n",
    "where $\\mathbf{x}$ is a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vec_dot(x, y):\n",
    "    assert len(x.shape)==2, \"rank of x != 2: not a matrix!\"\n",
    "    assert len(y.shape)==1, \"rank of y != 1: not a vector!\"\n",
    "    assert x.shape[1]==y.shape[0], \"x_cols != y_rows: shapes not compatible!\"\n",
    "    \n",
    "    x=x.copy()\n",
    "    y=y.copy()\n",
    "    z=np.zeros(x.shape[0])\n",
    "               \n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[0]):\n",
    "            z[i]+= x[i, j]*y[j]\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]].[2 3]=\n",
      " [ 8. 18.]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2], [3,4]])\n",
    "y=np.array([2,3])\n",
    "\n",
    "print(f\"{x}.{y}=\\n {naive_matrix_vec_dot(x, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "better way: make use of the vector dot product and multiply row vectors of x with column y:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vec_dot2(x,y):\n",
    "    assert len(x.shape)==2, \"rank of x != 2: not a matrix!\"\n",
    "    assert len(y.shape)==1, \"rank of y != 1: not a vector!\"\n",
    "    assert x.shape[1]==y.shape[0], \"x_cols != y_rows: shapes not compatible!\"\n",
    "    \n",
    "    x=x.copy()\n",
    "    y=y.copy()\n",
    "    z=np.zeros(x.shape[0])\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        z[i]=naive_vector_dot(x[i,:], y)\n",
    "        \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]].[2 3]=[ 8. 18.]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2], [3,4]])\n",
    "y=np.array([2,3])\n",
    "\n",
    "print(f\"{x}.{y}={naive_matrix_vec_dot2(x, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor dot product:\n",
    "\n",
    "$$ \\mathbf{z} = \\mathbf{x} \\cdot \\mathbf{y}$$\n",
    "\n",
    "where $\\mathbf{x}$ and $\\mathbf{y}$ ar shape-compatible  matrixices (i.e. `len(x_rows)=len(y_columns)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_tensor_dot_product(x, y):\n",
    "    assert len(x.shape)==2, \"Rank of x != 2\"\n",
    "    assert len(y.shape)==2, \"Rank of y != 2\"\n",
    "    assert x.shape[0]==y.shape[1], \"columns of x don't match rows of y!\"\n",
    "    \n",
    "    x=x.copy()\n",
    "    y=y.copy()\n",
    "    z=np.zeros((x.shape[0], y.shape[1]))\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            z[i,j]=naive_vector_dot(x[i,:], y[:, j])\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      ".\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "=\n",
      "[[ 7. 10.]\n",
      " [15. 22.]]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2], [3,4]])\n",
    "y=np.array([[1,2], [3,4]])\n",
    "print(f\"{x}\\n.\\n{y}\\n=\\n{naive_tensor_dot_product(x, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes of tensor products\n",
    "\n",
    "<img src=\"https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/02fig05.jpg\" width=400>\n",
    "\n",
    "The dot product between higher-dimensional tensors:\n",
    "\n",
    "$$(a,b) \\cdot (b,c) \\rightarrow (a, c)$$\n",
    "\n",
    "\n",
    "$$(a,b,c,d) \\cdot (d,) \\rightarrow (a, b, c)$$\n",
    "\n",
    "$$(a,b,c,d) \\cdot (d, e) \\rightarrow (a, b, c, e)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric interpretation of deep learning\n",
    "\n",
    "Think of it as a series of elementary tensor operations to transform representation of data into a format, where "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector addition: \n",
    "\n",
    "$$\\vec{a} + \\vec{b} = \\vec{c}$$\n",
    "\n",
    "this is an addition of two tensors of rank 1: \n",
    "\n",
    "<img src=\"https://dpzbhybb2pdcj.cloudfront.net/chollet/HighResolutionFigures/figure_2-8.png\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix rotation\n",
    "\n",
    "This is dot product of a matrix (tensor of rank 2) with a vector (tensor of rank 1):\n",
    "\n",
    "\n",
    "$$ \\mathbf{R} \\cdot \\vec{x} = \\vec{y}$$\n",
    "\n",
    "where\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{R} = \n",
    "\\begin{bmatrix}\n",
    "\\cos x & \\sin x \\\\\n",
    "-\\sin x & \\cos x\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation} \n",
    "\\begin{bmatrix}\n",
    "\\cos \\theta & \\sin \\theta \\\\\n",
    "-\\sin \\theta & \\cos \\theta\n",
    "\\end{bmatrix} \n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "x' \\\\\n",
    "y'\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can think of neural networks of chains of geometric transformations (tensor operations) of the input data.  These transformations take place in a high-dimensional space, implemented as long, chained, series of simple individual steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An image of \n",
    "\n",
    "Useful mental image:\n",
    "\n",
    "Imagine two sheets of coloured paper (red and blue) crumpled together into a ball.  The crumpled ball is the input data and each paper a class of the input data (red and blue).  The crumpled ball represents the input data. How do we unfold it to separate the individual sheets (classes of data)?  ML is figuring out the procedure of trasformations that perform this separation, very much like the sequential number of individual operations you'd perform to 'uncrumple' the pieces of paper, picking one corner at a time, stretching, unfolding, shearing, etc.:\n",
    "\n",
    "\n",
    "<img src=\"https://dpzbhybb2pdcj.cloudfront.net/chollet/HighResolutionFigures/figure_2-9.png\" width=600>\n",
    "\n",
    "This is what ML is about: finding neat representations for complex, highly folded data manifolds. The complex transformation required is broken down into  a series of simple elementary ones - similar to what you would do to unfold the crumpled piece of paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-based optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
