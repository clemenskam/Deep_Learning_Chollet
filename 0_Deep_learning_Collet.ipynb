{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning: Chapter 2\n",
    "\n",
    "\n",
    "Example:  Classify handwritten digits\n",
    "\n",
    "* grayscale images, 28x28 pixels into 10 categories\n",
    "* [MNISt](https://en.wikipedia.org/wiki/MNIST_database) dataset: 60k training images, 10k test images\n",
    "\n",
    "\n",
    "Terminology:\n",
    "\n",
    "* **Class**: a category in a classification problem \n",
    "* **Sample**: datapoints\n",
    "* **Label** class associatied with a specific sample\n",
    "\n",
    "MNIST database is preloaded in KERASin set of four Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `train_images` and `train_labels` frm the training set\n",
    "* `test_images` and `test_labels` is test set on which model will be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train_image = (60000, 28, 28)\n",
      "Length train_labels = 60000\n",
      "Shape test_images= (10000, 28, 28)\n",
      "Length test_labels = 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape train_image = {train_images.shape}\")\n",
    "print(f\"Length train_labels = {len(train_labels)}\")\n",
    "print(f\"Shape test_images= {test_images.shape}\")\n",
    "print(f\"Length test_labels = {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow: \n",
    "\n",
    "1. feed neuronal network training data\n",
    "2. associate images with labels\n",
    "3. produce predictions for test images\n",
    "4. verify whether predictions match test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* layer: is a filter\n",
    "* layer extract representations of data fed into them.\n",
    "* layers are chained\n",
    "\n",
    "Network above consists of a sequence of two dense layers that are *densely* connected (or *fully* connected) neural layers. The second layer is a 10 way *softmax* layer which rturns 10 probability scores (summing to 1). Each score will give probability that current digit belongs to one of the 10 digit classes.\n",
    "\n",
    "Make network ready for training need to pick three more things as part of the *compilation* step: \n",
    "\n",
    "* optimizer (method to update network)\n",
    "* Loss function (how network measures performance on training data)\n",
    "* Metrics to monitor during training and testing (here: accuracy of classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* reshape images into a `float32` array of shape (60000, 28*28)\n",
    "* rescale 8 bit images into values in interval `[0, 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 *28))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* categorically encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train network.  Call network's fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/clemenskaminski/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2562 - accuracy: 0.9264\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1041 - accuracy: 0.9694\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0680 - accuracy: 0.9804\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0498 - accuracy: 0.9857\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0377 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63f273f90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs =5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 37us/step\n",
      "test_acc: 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is lower than the training set accuracy.  This is an example of *overfitting*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data representations for neural networks\n",
    "\n",
    "Tensors:\n",
    "\n",
    "* rank 0: scalar `0`\n",
    "* rank 1: vector `[1,4,5,7]`\n",
    "* rank 2: array  `[[11,12,13], [21, 22, 23]]`\n",
    "* rank n: has n axes\n",
    "\n",
    "note: vector `[1,4,5,7]` has 4 dimensions, but is a tensor of rank 1 (often one speaks, inaccurately, of a one dimensional tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of data:\n",
    "\n",
    "* Vector data: e.g. dataset of dext documents where each is represented by the counts of how many times each word in a dictionary appears in it.  e.g. tensor of shape `(500, 20000)` might describe 500 documents with dictionary of 20000 words.\n",
    "\n",
    "* Time series data: E.g.stock prices as a tensor of rank 3: 250 days with values every minute (390 working minutes per day), recording low, high and current price for each minute `(250, 390, 3)`\n",
    "\n",
    "* Image data: tensor of rank 4: e.g. 128 images, 256 x 256 pixels, 3 colour channels. `(128, 256, 256, 3)`. note Tensorflow convention for order is `(samples, height, width, color_depth)` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor attributes\n",
    "\n",
    "* Number of axes (rank)\n",
    "* shape: dimension of tensor along each axis\n",
    "* Data type (usually `dtype` in python libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_images =  (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print('shape of train_images = ', train_images.shape)  #Note: above we have vectorised 28x28 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y = (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "y = np.reshape(train_images, (60000, 28,28)) #reshape into tensor of rank 3 (sample, height, width)\n",
    "print('shape of y =', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit = y[3]\n",
    "digit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = y[34001]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing tensors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing just bottom half of 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = y[34001, 15:, :]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAA3CAYAAACvkJk/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAARdklEQVR4nO2deVyU1f7H38OwCEKgrEKkIA7uuQvRqj81xep20+pGmxnuRWV1+9VPzeV2KzSX3NFXdctrC+6h0s9rlikUaNxyARQXzB0FRFGc7f5xZh5AWRSZ5xm95/3PPHOeZb7PzJzv+Z7P+Z7z6KxWKxKJRCJRBxetDZBIJJL/JqTTlUgkEhWRTlcikUhURDpdiUQiURHpdCUSiURFpNOVSCQSFXGta2c/l6FOn0/2/5ZvdHXtl/egDvIenAN5D85BXfcgI12JRCJREel0JRKJREWk05VIJBIVkU5XIpFIVEQ6XYlEIlGROrMXJBKJtuijowA4kBCIX4/TSnmTj5sB4LEhSxO7JA1Hc6fr2iKEM31aAVD8cDmDo3YB8EiznYza+TQAEeNLMR0+opWJ1dB5eABQcX8nPN86BoDlTX+s2cJu5KptkkYiP6UnB+NTat65VLwMCO2inkH/RZwdFkvmtHkADEh4Ef2WnY12bSkvSCQSiYpoEunq2xs4+p4egH91X0IzF88aj/s99h8ARL83nNYJzhHpXux3JwCbFy1Uyp74qD9l99naL6tZC7MktwiHp8TSf1A2AOmhKaSVNwFgYvIwAhZlKMfkvrhANZv0fr4A5M6KwrfZBQCmdVhNvNcl3j7ZGYCvdnWnxRp3AJqm/qyabY7C9fFT6HWiTp/p0ISgLY147ca7VN1UDOrJ8ecqAPjt7qW4orft8WT1BT8A/pY7kOKTtwHg4XuJ3XGfAfBkh2yylOO1pfDhq+WDHbkRGCxFGljTQHRisoy+bRQHhwYCUBFY2Vj45ukJTtkBgLWiQil38fLCajZfVe4IikbGkjlxLgDjj8ew/6k7ADDnF9R5nl0DPXlfID5HTIDz655FI2OJS7Q72kpnGpGWiCFR2B5ARrVz7M5YDc5/1RyAfR2rSx1mK0wNygFgap8cTH3Ef2PyO93ZOjUWAK+VN5kDttWNcJ8SpSj02yOYGvEjpLwgkUgkKuLQSNeliWiNC1/rxvejk/FXZAQ9Wy65ATBibSJt5xwHIPBgHoG2IwqSYyFObK8q6Mzt7HakqddE+Z97k9rvY9s7zccgrxudmztlj3aj4+v/BmB+2Fe1HtvZZxwAd6w7y+VZ5QBsbLeKQtNFAB5c/gaRb2XUev6NEvviTow2qWZGi0ySlomezuYNsbScWPvnRn4hZKjUFv/kvhwxEOuxwWFmNpiikbFcCBPbV0oFEWmJAEqUeyW5Ly6g++TRwNURsCPo3PyYsn3RehmA/uNfwW/HSYwtRC+1cEATuj+QC8D74esImHIegFXWfnitunmi3YLk3gDsj1yI4YfnAIg8trdRP8OhnuPUs10B2D1uPtAUs9UCQPufniciYQ8AUabMaqG7rmcnANIfT0av8wYg4JOmjjTzmjmbcJ4u7ld/ZW0+NWpgzbXj0rEtAKFL/mBx+HwsCIlkUO4jHMoMByAkw8yxu4VjWzh0MZtGfwhA1gtBxHuJCpRz2czbB54EYNaQT5jzVluH2Tw37GeMVmGPm07P7NBt4l6Gb8cy3Eq/F0cBQjqwSwqRXxxhdqhwQhb06HTOmUlSkyZrlwvivS7RbnoxAFeODhyeEms7NlfRd9WgYFgEAClf/0Gir2jULj5Vgt9OHS5bfwWg1VY4Yzt+RNeRHJ0ovvvVs2bwPOMBnN/5uui5K074pWJzOaGfC43aarzcuB/TqFeTSCQSSZ04NNIN2i5a7I3lHhQa/Zm3+E8ARH15AJOpZmn60EMium3l6sXi0lAAvA6dw+JIQxvIwtKWALjmHbkqKnEWXDq25bkV6QA85l1Et6yn8Z8veg5u32XTij+UYw3ZwQCs6NuT+0O3AxDvdV65z7QhsbAnH4A5OC7KBTBazYq8YH8PIuo1Ws28NmcZAFPzBtM7+DAAH7bYisU24Gq0mrFa61whUHXskao9yrVHt8kvPUPZHaIqjg+DlnlXR7H66CjlvO6TR6siK9ix7BKywbr4Hsz76D4Acnp9wcI1LVkf3w0A08HD6FzFPej2FhD6ZzHQmtg3CXOAc/0OtXHwvV6ktxTfccS3SRjWO2YA1qFO1/5jze7aC0tZGSGIilzbSKCpb3eyX5hpO0bPPyY8BEDTXc7ZLVnwmbAvrGi7xpbUTu4r3gz1Fh2/qO9GYBi2o8bjTH27E/NRJgATA36nwip+pY6bR9HuzaMAmE/kO9ze4rQ2ALjpcpSyuJwnObcjAID+g7KZ0SJTkTwGdl2OC6JSW9Ar2246PWU7/QFo7nCr6yc6263WzAQPsvCwlQfUcn7UssOKk1ZTWqiK6eBhwt8QUsOYf8YxP2wbTTcI5zpjyRDK7xR6/5COv3Lwgr/trEP8+6gQrz1KeuL+nW2SgcV5whR7StxfH1mllDXPdpxrlPKCRCKRqIgqQ/CWsrI69+vbRALwTspSPHVCvG7/yVhapWrToteEPsCfUW1/qlYW9n3d9+UMuJ9wU7Y9Cj2q7XPx8WHfux0AyHlilvLdb7nkxtvvjgWgzecZjZqjWB92SaCqvND0Yz+abRT/hW1/xGKcuA03XaWMUNt2XVkOalG6XgzyzQlNVcq6Tx6N4RqjVfsg4ZzQVNouERkLLVWUFq7E2kT8h25zvQTAMz4nxOurc2s/KcL2ejd0SxZZMSGznKd3eOC19gAM9/2BiLUjADAs+cVhn6d93lNMZ/ov/RGAOA8LD+x6DICId7NwprFnnY83Y/wOKu+nFXVEf1D84Zyno3Q1rafvIfdp0QWMG/AbR6e5Y7xXZIjc/VEm3wbMtx3pTo/spwAIHXMOv6PqV2x9dJSiz9qdJ4D7xkptLWBxBo8u7kXFwJ4AXBhbSmbXL5Vz7PLC68fvBS6pZHnNlK6PIrNL6lXlwVtOX/N/5uzMym2tGxFdz068ulx81309r54cs+OyuKtRH7xM0NJKGevkyB4AWPTgUepMtRos93Tl62fFl7z2QnPazbZljjhQ/tDM6doXjgn4qJCX/A4AkHPZhPc4UWnMtQy0aY19auCPp6NwPV2osTX1Yy4pZULhwwB80zqd/1n/KKvbiajEW+ehaLd3fpFE6wmiopgaOUXmmrFasXB1pFsT9llmHhvActSqnGN31r8s6oq/RhGhMmDWZYGiw6aXdGJOqLB5bNq3JL/0TL0z5fTRlU5b7cGzqrj4+AAQtzRLcbYLS1syfeuD2H4u9scvws9F/G+CtxdjqfIfCprrPFHtlXhOO05nd/EbjX7zWbz3Zjr8M6WmK5FIJCpyw5Guvr2B8pZi9O/Yva5ExYjuYSvvs1w0Cz1xy14D4aFnOVUq0sH6ROwjxmc/AAk+p5RrXbK6UjBNHGM6GkPzXaIZDUzdjfncuRs19YY431GkU9kneJR8E0YAzh/pAhxb3FpsfACb2q8C21j5pNN3sv31XgBEbsrQXM4x5xeweYOIEl2Gb7dJBFCfTFA1YyEuR0ze8F+iTVRYNbUrrbwJc6LsqXVGIlLETLOHuubQeWoOefXMlHOGjAWAA292BOBb/3n02im+3+CEExjOZeHi5QXA7LuiSGom6vTF233w+E0bW6+HsidjWNF6Fo8fiAfAd+MeVaTCBjvd/AWisqY+OLfGWVrVCP+hzt3nLKJSnTCF8F7X1QCsCu/GzyGtAPDb11qZ+aI29tzDZq+LxmTSabHKWPDy3U6t5dq5MKQ3r01cXq3M8NUYAKKn5uFWXHMKmVbYdcveR8YS9IO9Qa57kRv7DDuj1cz/GdIAmPlgQjUtWC2qarDz4gcD+5X39hSxvHquUTRSNDzpoQsY9MAQW+n+2k9wMGavyuZYt1qkgpnPifRBS7mYIj73h34k/Uk7GxtCyvszcdO5ciJZBCWe5xw3eFYVKS9IJBKJijQo0r34SC92PyQGY9x0epKOiZZ5b2kwhTtFIrTpNjORUSeUcwI9z7Os1Sbl/bpysYTjxIXPcvsGsSyieU/V5PsSIslBa+yR7ooo0Rdcli0WxDCcy9bMpnpx0VOQLEb3dzwxE29dZapYrrGC6Pf2AWAuLtbEvGvBPyXjmnoSxWltcEEk3Lvp9EzLF13FZipHufbUrswuqZWL0dQws6w+Kgb2ZMckIU/E5AzBN0/76LFHjKiXZywXab6nvMZjwv4FiAmnFEe7EbJeJeMawOlRwl9FuP5C2/TRGNaoE+HaaZDTNY46g9FWJeL+9gpB87fbLlZIZA06p96/OSe/9KlWNv1/EwBokbrdqbvp+6d0tW1tJ+eyCcNix64jeyO4thJrzpYsdCWvkz0VzIMRR4Q2ujj8R5YV98ZcdKaWK9x8WK26avKCVlN/DyQEKtsN0V/tTnvL0sqFy30Hae9wAbIzDQD4t/KkPEzYduUSVJ4nK+vFc8M3kj7zNrXMu24yJswBIM9oof2kE6rmoYOUFyQSiURVGhTp3hV0kFJb8nBoWs2rqus8PCgZKqLECe9+yoOe5eRcFkcmfphE4ArH58M1BlZ95SBCF3dXStqK7Ao/dXsk9aJv1ozT84SMkNHpKw6ZRDdwwNdv4NpSrFNA+I+sXnk34Thv3uT1otNZnWK9BXvGQkzOEHyvc9Cr6lKPaeVNbANwoOXgWW2U3S7yoK+MdF2LyymwrbXcp+le0umtsmV1Y5cJ903vgYdtXY9hf3+ZgCPqZ4U0yOkWnA8kLESkity5+jCbZ9wFQHE7HZdDxNqyk+LW8oxP5Q1NONWFX4eJ1JPAHO2nZ95qHB7djt+6CJ0933iJMSNfAcA60Ko89ujjkkgilhxQvTvlSK6UF7SetdUr6HC92Qn66CgOJAQy46lPAIj3ylEkBZFi5lzO1rBEyFEFQy5yMeZ8zQeZzFyyOscjtWpC5ykeoFDw+ELyjeI5b8Er8jWRNqW8IJFIJCrSoEj3j88jYbLYnhqUw9QPas4y+OBMOwBWzu5DwGdZWE17GmalpF6WJc5Eb8tSeHbyeCo6iC73nqGzOWMRUzJXvtMfz+NOpovcIFXlBWdYb2FOaBYvZ4vMkW0pPZTyC2Hg1+M0wFXrMUSkJSpPi3C2KBfAvFdkuwzcOo6xXUTO/apHqz+GxxToQwc3sWDS75ed60kqOjd3cmdF295tJXHsqwA0KdKmLjTI6QZ8toN7zosE+9KhZTwfLfTZcrMHn2YLqSHgJzf8PxdpO/4m7Wc73er4uhgxW8UMwLWTk2muFw7YbLXSP/kNAIJX3zparn3Bm7cNyxV5Qcv1FuxpYjsmLVDWWGBSzWlraeVNGPf9M8pkCQNZTp3BY6fFaneSHhCNwuakaIyrdWB1/pqtDwvh4MAlAJwyX8AzXQSJWlku5QWJRCJRkQZFulbjZXy+FNGtz5ewicocXAOVkwacvw28Pj4vC8F/rZBInC0y6btuPPseFSPgQXovlpUFAZDy9mMEr7x1Ilw7ZeHirxvvVarIC2j4VBh7bu6ARV2Uabxuj5xW9pdkBxKSIYYwPTZkYUD9Kco3ive6HIaNvx+ANW3SiE4eg2GRmKp9JNZLOe6o2VcL82rlQodgZTtm5XjaGLXNnNJ+PV0nx/B3oWfxJEz/ZAhhJc7pwNq8nM3gv94DQNnAjnivEWtVeBmd81FHjUXV5Rx7jfiVghSNDaLK5IhFlWXXm0bmjFgrKjj0vlh75Py8dPL+Mh/+UrnfnqY4fdxI3J2oUTnRy40is8hYaJOkfaqqlBckEolERWSkWw/2KbODwroR5syTCixmLBdEa9409edbTtq5Ep8joqu+6aKf8pDK2aHb6DRFPA5G63zdWxVP2zoFfQNew/BCLgdKxWSUU0W3EbpGDOQ23ehcvauWk7aTMClOazMUpNOV3JTYn7owNW8wA7uKpSsN60ZjkM5WFfyXZnBmKfgiUt2cS8V1bqS8IJFIJCoiI13JTU3zwfkMpjsABm6tiR+SWxOd9SZIbpZIJJJbBSkvSCQSiYpIpyuRSCQqIp2uRCKRqIh0uhKJRKIi0ulKJBKJikinK5FIJCryH7BBvvzeAxxLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter=0\n",
    "start_index = 1011\n",
    "tiles = 7\n",
    "images = y[start_index:start_index+tiles]\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "for i in range(1,len(images)+1):\n",
    "    sub = fig.add_subplot(1, len(images), i)\n",
    "    sub.axis('off')\n",
    "    sub.imshow(images[i-1])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data batches\n",
    "\n",
    "the first axes (axis 0) is called the **sample axis**.  Usually the entire dataset can't be processed at once and one needs to break the dataset into smaller **batches**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1 = train_images[:128]\n",
    "\n",
    "batch_4 = train_images[128*4:128*(4+1)]  #batch n is from dataset[128*n:128*(n+1)] \n",
    "\n",
    "len(batch_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All transformations learned by DNN can be reduced to a small number of tensor operations (add, multiply, etc)\n",
    "\n",
    "E.g.\n",
    "```python\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape=(28 * 28,)))\n",
    "```\n",
    "\n",
    "this layer cab be interpreted as a function that takes a 2D tensor (vecor samples) and returns another 2D tensor.\n",
    "\n",
    "The function is:\n",
    "\n",
    "```python\n",
    "output = relu(dot(W, input) + b\n",
    "```\n",
    "\n",
    "* This includes a dot product between a 2D tensor W and an input tensor and adds a vector b. \n",
    "* It also includes a **rectified linear unit** function defined as `max(x, 0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectified linear Unit - relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    '''Naive implementation of relu (rectified linear unit) function\n",
    "    takes tensor x of rank 2\n",
    "    ''' \n",
    "    assert len(x.shape) == 2, 'x has more than 2 axes, not an image!'\n",
    "    x = x.copy()    #produce a copy of x without overwriting input tensor\n",
    "   \n",
    "    \n",
    "    for i in range(0, x.shape[0]):\n",
    "        for j in range(0, x.shape[1]):\n",
    "            x[i, j]=max(x[i,j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=\n",
      "[[ 0.15304079  0.11658962  0.25870324 -0.55225153]\n",
      " [-0.28590247  0.30955119 -0.67407404 -0.76107192]\n",
      " [-0.03593688  0.42629766  0.23669738  0.62289514]] \n",
      "\n",
      "Relu(x) = naive_relu(x) =\n",
      "[[0.15304079 0.11658962 0.25870324 0.        ]\n",
      " [0.         0.30955119 0.         0.        ]\n",
      " [0.         0.42629766 0.23669738 0.62289514]]\n"
     ]
    }
   ],
   "source": [
    "x = 2.0*(np.random.random((3,4))-0.5)  #random.random only produces positive numbers in (0, 1)\n",
    "\n",
    "print(f\"x=\\n{x} \\n\")\n",
    "print(f\"Relu(x) = naive_relu(x) =\\n{naive_relu(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same is achieved with the very simple inbuilt numpy method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relu(x) = np.maximum(x, 0) =\n",
      "[[0.15304079 0.11658962 0.25870324 0.        ]\n",
      " [0.         0.30955119 0.         0.        ]\n",
      " [0.         0.42629766 0.23669738 0.62289514]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Relu(x) = np.maximum(x, 0) =\\n{np.maximum(x,0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_addition(x, y):\n",
    "    assert len(x.shape)== 2, \"Shape of x or y not rank 2!\"\n",
    "    assert x.shape == y.shape, \"Shape of x and y not same!\"\n",
    "    \n",
    "    x=x.copy()\n",
    "    y=y.copy()\n",
    "    \n",
    "    for i in range(0, x.shape[0]):\n",
    "        for j in range(0, x.shape[1]):\n",
    "            x[i,j]+=y[i,j]\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =\n",
      "[[2 3 2]\n",
      " [3 4 0]]\n",
      "b =\n",
      "[[4 2 4]\n",
      " [1 1 4]]\n",
      "a + b = naive_addition(a, b) =\n",
      "[[6 5 6]\n",
      " [4 5 4]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(5, size=(2,3))\n",
    "print(f\"a =\\n{a}\")\n",
    "\n",
    "b = np.random.randint(5, size=(2,3))\n",
    "print(f\"b =\\n{b}\")\n",
    "\n",
    "print(f\"a + b = naive_addition(a, b) =\\n{naive_addition(a, b)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Means stretching dimensions of lower rank tensor to those of higher rank tensor for efficient computation.\n",
    "\n",
    "See [broadcasting article](https://numpy.org/devdocs/user/theory.broadcasting.html)\n",
    "\n",
    "* works from last axis backward to front\n",
    "* final dimensions must match\n",
    "\n",
    "E.g. adding `1` to `[1,2,3]` is the same as broadcasting `1` to `[1,1,1]` and adding `[1,1,1]` to `[1,2,3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,4)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=\n",
      " [[[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]]\n",
      "\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]]]\n",
      "\n",
      "rank of y: 3\n",
      "\n",
      "shape of y: (2, 3, 10)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(1,11).astype(float)\n",
    "y = np.ones((2, 3, 10)).astype(float)\n",
    "y[:]=x\n",
    "print('y=\\n',y)\n",
    "\n",
    "print('\\nrank of y:', y.ndim)\n",
    "\n",
    "print('\\nshape of y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix rotation\n",
    "\n",
    "$$ x \\cdot R = y$$\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{equation}\n",
    "R = \n",
    "\\begin{bmatrix}\n",
    "\\cos x & \\sin x \\\\\n",
    "-\\sin x & \\cos x\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation} \n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{pmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\cos \\theta & \\sin \\theta \\\\\n",
    "-\\sin \\theta & \\cos \\theta\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "x' \\\\\n",
    "y'\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-based optimisation\n",
    "\n",
    "each neural layer transforms input data as follows:\n",
    "\n",
    "```\n",
    "output = relu(dot(W, input) +b)\n",
    "```\n",
    "\n",
    "where W and b are tensors that are attributes of layers, called weights (*kernel*) or trainable parameters (*bias*) of the layer.  Initially, this does nothing useful, but gradually W and b are adjusted, based on feedback signal.  This adjustment takes place in a *training loop*.  Specifically\n",
    "\n",
    "1. Draw batch of training samples `x` and corresponding targets `y`\n",
    "1. Run network on `x` (called *forward pass*) to obain `y_predicted`\n",
    "1. Compute loss of network on batch, a measure of mismatch between `y_predicted` and `y`\n",
    "1. Update  weights of `W`, `b` so that loss is reduced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat, until loss is low: The network has now learned to map inputs to their correct targets.  \n",
    "* Step 1 is simple: just I/O code.\n",
    "* Steps 2 and 3 are merely application of a handful of tensor ops.\n",
    "* Step 4 is the difficult part.  How do we decide whether `W` and `b` coefficients should be increased or decreased? And by how much?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could do latter by freezing all coefficients except one, which you vary and recalculate loss.  If loss greater, change coefficient accordingly, etc.  Repeat sequentially for all coefficients. Problem: Terribly inefficient! There may be 10s or even 100s of thousands of coefficients to optimise: this makes problem intractable.  However: all operations described are differentiable. Better way: compute **gradient** of the loss wih regards to network coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivative:**\n",
    "\n",
    "Approximate `f` around a point `p` as:\n",
    "\n",
    "`f(x + epsilon_x) = y + a * epsilon_x`\n",
    "\n",
    "The slope `a` is called the derivative of `f` in `p`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vector dot product\n",
    "\n",
    "\n",
    "$$ z = \\vec{x} \\cdot \\vec{y}$$\n",
    "\n",
    "where $z$ is a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x,y):\n",
    "    assert len(x.shape)==1, \"rank != 1: x not a vector!\"\n",
    "    assert len(y.shape)==1, \"rank != 1: y not a vector!\"\n",
    "    assert x.shape[0]==y.shape[0], \"len(x) != len(y): shapes incompatible!\"\n",
    "    \n",
    "    x=x.copy()\n",
    "    y=y.copy() #ensures that original x, y not overridden\n",
    "    z=0.0\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        z+=x[i]*y[i]\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3].[4 5 6]=\n",
      " 32.0\n"
     ]
    }
   ],
   "source": [
    "x=np.array([1,2,3])\n",
    "y=np.array([4,5,6])\n",
    "\n",
    "print(f\"{x}.{y}=\\n {naive_vector_dot(x, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix - vector product:\n",
    "\n",
    "$$ \\vec{z} = \\mathbf{x} \\cdot \\vec{y}$$\n",
    "\n",
    "where $\\mathbf{x}$ is a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vec_dot(x, y):\n",
    "    assert len(x.shape)==2, \"rank of x != 2: not a matrix!\"\n",
    "    assert len(y.shape)==1, \"rank of y != 1: not a vector!\"\n",
    "    assert x.shape[1]==y.shape[0], \"x_cols != y_rows: shapes not compatible!\"\n",
    "    \n",
    "    x=x.copy()\n",
    "    y=y.copy()\n",
    "    z=np.zeros(x.shape[0])\n",
    "               \n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[0]):\n",
    "            z[i]+= x[i, j]*y[j]\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]].[2 3]=\n",
      " [ 8. 18.]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2], [3,4]])\n",
    "y=np.array([2,3])\n",
    "\n",
    "print(f\"{x}.{y}=\\n {naive_matrix_vec_dot(x, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "better way: make use of the vector dot product and multiply row vectors of x with column y:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vec_dot2(x,y):\n",
    "    assert len(x.shape)==2, \"rank of x != 2: not a matrix!\"\n",
    "    assert len(y.shape)==1, \"rank of y != 1: not a vector!\"\n",
    "    assert x.shape[1]==y.shape[0], \"x_cols != y_rows: shapes not compatible!\"\n",
    "    \n",
    "    x=x.copy()\n",
    "    y=y.copy()\n",
    "    z=np.zeros(x.shape[0])\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        z[i]=naive_vector_dot(x[i,:], y)\n",
    "        \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]].[2 3]=\n",
      " [ 8. 18.]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2], [3,4]])\n",
    "y=np.array([2,3])\n",
    "\n",
    "print(f\"{x}.{y}=\\n {naive_matrix_vec_dot2(x, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor dot product:\n",
    "\n",
    "$$ \\mathbf{z} = \\mathbf{x} \\cdot \\mathbf{y}$$\n",
    "\n",
    "where $\\mathbf{x}$ and $\\mathbf{y}$ ar shape-compatible matrices (i.e. `len(x_rows)=len(y_columns)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
